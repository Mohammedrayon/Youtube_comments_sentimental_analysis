{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe91c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "# Import functions for data preprocessing & data preparation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from string import punctuation\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d10ce3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Comment'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\Mohammed Rayon\\Desktop\\machine_learning\\sentiment analysis\\commentscraperfile.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0633775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HahahağŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is moaning like his butt got fucked ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So not cool! Btw he tapped out twice and you s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best part. There there. Pat's on the back.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he sounds like a bata-male. or a women.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment\n",
       "0  HahahağŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚...\n",
       "1        He is moaning like his butt got fucked ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
       "2  So not cool! Btw he tapped out twice and you s...\n",
       "3         Best part. There there. Pat's on the back.\n",
       "4            he sounds like a bata-male. or a women."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c73e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Removing the unwanted columns\n",
    "# data1=data.drop(['Unnamed: 0','Likes','Time','user','UserLink'],axis=1)\n",
    "# data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace49bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HahahağŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Comment'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbeb246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab9c981c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HahahağŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is moaning like his butt got fucked ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So not cool! Btw he tapped out twice and you s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best part. There there. Pat's on the back.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he sounds like a bata-male. or a women.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment\n",
       "0  HahahağŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚...\n",
       "1        He is moaning like his butt got fucked ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
       "2  So not cool! Btw he tapped out twice and you s...\n",
       "3         Best part. There there. Pat's on the back.\n",
       "4            he sounds like a bata-male. or a women."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51a18479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Mohammed\n",
      "[nltk_data]     Rayon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HahahağŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is moaning like his butt got fucked ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.420</td>\n",
       "      <td>-0.5106</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So not cool! Btw he tapped out twice and you s...</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.671</td>\n",
       "      <td>-0.4464</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best part. There there. Pat's on the back.</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he sounds like a bata-male. or a women.</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Positive  Negative  \\\n",
       "0  HahahağŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚...     0.000     0.000   \n",
       "1        He is moaning like his butt got fucked ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚     0.175     0.406   \n",
       "2  So not cool! Btw he tapped out twice and you s...     0.107     0.222   \n",
       "3         Best part. There there. Pat's on the back.     0.375     0.000   \n",
       "4            he sounds like a bata-male. or a women.     0.333     0.000   \n",
       "\n",
       "   Neutral  Compound Sentiment  \n",
       "0    1.000    0.0000   Neutral  \n",
       "1    0.420   -0.5106  Negative  \n",
       "2    0.671   -0.4464  Negative  \n",
       "3    0.625    0.6369  Positive  \n",
       "4    0.667    0.3612  Positive  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Labeling the dataset\n",
    "nltk.download('vader_lexicon')\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "data1[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data1[\"Comment\"]]\n",
    "data1[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data1[\"Comment\"]]\n",
    "data1[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data1[\"Comment\"]]\n",
    "data1['Compound'] = [sentiments.polarity_scores(i)[\"compound\"] for i in data1[\"Comment\"]]\n",
    "score = data1[\"Compound\"].values\n",
    "sentiment = []\n",
    "for i in score:\n",
    "    if i >= 0.05 :\n",
    "        sentiment.append('Positive')\n",
    "    elif i <= -0.05 :\n",
    "        sentiment.append('Negative')\n",
    "    else:\n",
    "        sentiment.append('Neutral')\n",
    "data1[\"Sentiment\"] = sentiment\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37a82d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HahahağŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is moaning like his butt got fucked ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So not cool! Btw he tapped out twice and you s...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best part. There there. Pat's on the back.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he sounds like a bata-male. or a women.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Sentiment\n",
       "0  HahahağŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚...   Neutral\n",
       "1        He is moaning like his butt got fucked ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚  Negative\n",
       "2  So not cool! Btw he tapped out twice and you s...  Negative\n",
       "3         Best part. There there. Pat's on the back.  Positive\n",
       "4            he sounds like a bata-male. or a women.  Positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Droping the unwanted columns\n",
    "data2=data1.drop(['Positive','Negative','Neutral','Compound'],axis=1)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c88bf262",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "porter_stemmer = PorterStemmer()\n",
    "lzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "625929ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = [\n",
    "    'no', 'very', \"don't\", \"aren't\", \"couldn't\", \"didn't\",\n",
    "    \"doesn't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\",\n",
    "    \"mustn't\", \"needn't\", \"shan't\", \"shouldn't\", \"wasn't\", \"weren't\",\n",
    "    'won', \"won't\", \"wouldn't\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b89c3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=[word for word in stop_words if word not in st]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97692035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text):   \n",
    "    # convert text into lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove new line characters in text\n",
    "    text = re.sub(r'\\n',' ', text)\n",
    "    \n",
    "    # remove punctuations from text\n",
    "    text = re.sub('[%s]' % re.escape(punctuation), \"\", text)\n",
    "    \n",
    "    # remove references and hashtags from text\n",
    "    text = re.sub(\"^a-zA-Z0-9$,.\", \"\", text)\n",
    "    \n",
    "    # remove multiple spaces from text\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    \n",
    "    # remove special characters from text\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "\n",
    "    text = ' '.join([word for word in word_tokenize(text) if word not in stop_words])\n",
    "    \n",
    "    # stemming using porter stemmer from nltk package - msh a7sn 7aga - momken: lancaster, snowball\n",
    "    text=' '.join([porter_stemmer.stem(word) for word in word_tokenize(text)])\n",
    "    \n",
    "    # lemmatizer using WordNetLemmatizer from nltk package\n",
    "    text=' '.join([lzr.lemmatize(word) for word in word_tokenize(text)])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03db25f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Mohammed\n",
      "[nltk_data]     Rayon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#copying the data \n",
    "nltk.download('omw-1.4')\n",
    "data_copy = data2.copy()\n",
    "data_copy.Comment = data_copy.Comment.apply(lambda text: text_processing(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7feefd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the text values to numeric\n",
    "le = LabelEncoder()\n",
    "data_copy['Sentiment'] = le.fit_transform(data_copy['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09b9e2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hahaha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moan like butt got fuck</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cool btw tap twice still help beyond danger ev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best part pat back</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sound like batamal woman</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Sentiment\n",
       "0                                             hahaha          1\n",
       "1                            moan like butt got fuck          0\n",
       "2  cool btw tap twice still help beyond danger ev...          0\n",
       "3                                 best part pat back          2\n",
       "4                           sound like batamal woman          2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = {\n",
    "    'Sentence':data_copy.Comment,\n",
    "    'Sentiment':data_copy['Sentiment']\n",
    "}\n",
    "\n",
    "processed_data = pd.DataFrame(processed_data)\n",
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "856f87e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2954\n",
       "1    2434\n",
       "0    2339\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8da5e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resmapleing teh dataset\n",
    "df_neutral = processed_data[(processed_data['Sentiment']==1)] \n",
    "df_negative = processed_data[(processed_data['Sentiment']==0)]\n",
    "df_positive = processed_data[(processed_data['Sentiment']==2)]\n",
    "\n",
    "# # upsample minority classes\n",
    "# df_negative_upsampled = resample(df_negative, \n",
    "#                                  replace=True,    \n",
    "#                                  n_samples= 205, \n",
    "#                                  random_state=42)  \n",
    "\n",
    "# df_neutral_upsampled = resample(df_neutral, \n",
    "#                                  replace=True,    \n",
    "#                                  n_samples= 205, \n",
    "#                                  random_state=42)  \n",
    "\n",
    "\n",
    "# Concatenate the upsampled dataframes with the neutral dataframe\n",
    "# final_data = pd.concat([df_negative_upsampled,df_neutral_upsampled,df_positive])\n",
    "final_data = pd.concat([df_negative,df_neutral,df_positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1b7238c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2954\n",
       "1    2434\n",
       "0    2339\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "944c8c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moan like butt got fuck</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cool btw tap twice still help beyond danger ev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>omg felt bad liter want hug</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>didnt bring fact exact thing put hot sauc hamb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>could die</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Sentiment\n",
       "1                            moan like butt got fuck          0\n",
       "2  cool btw tap twice still help beyond danger ev...          0\n",
       "6                        omg felt bad liter want hug          0\n",
       "7  didnt bring fact exact thing put hot sauc hamb...          0\n",
       "9                                          could die          0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eda518a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moan like butt got fuck',\n",
       " 'cool btw tap twice still help beyond danger even prank',\n",
       " 'omg felt bad liter want hug',\n",
       " 'didnt bring fact exact thing put hot sauc hamburg ultim reveng',\n",
       " 'could die']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "for sentence in final_data['Sentence']:\n",
    "    corpus.append(sentence)\n",
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2934c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = final_data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1121287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the vectorizer to a file\n",
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(cv, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "844502b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6bed94d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "872b2ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b80c9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# classifier = GaussianNB()\n",
    "# classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd25b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f092b8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8085381630012937\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77       486\n",
      "           1       0.80      0.85      0.83       475\n",
      "           2       0.80      0.84      0.82       585\n",
      "\n",
      "    accuracy                           0.81      1546\n",
      "   macro avg       0.81      0.81      0.81      1546\n",
      "weighted avg       0.81      0.81      0.81      1546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Generate a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "658877f7",
   "metadata": {},
   "outputs": [],
   "source": [
    " import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7845c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='trained_model.sav'\n",
    "pickle.dump(rf_model,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b55a6ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "loaded_model = pickle.load(open('trained_model.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3233b67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter comments : This product is very bad  and doesnoyt worth the money\n",
      "DataFrame:\n",
      "                            Comment\n",
      "0  product bad doesnoyt worth money\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prompt the user for input\n",
    "s = input(\"Enter comments : \")\n",
    "user_input=text_processing(s)\n",
    "# Split the input into a list of comments\n",
    "comments = user_input.split(',')\n",
    "\n",
    "# Create a dictionary with the 'comment' column\n",
    "data = {'Comment': comments}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(\"DataFrame:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2ec8eb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'product bad doesnoyt worth money'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Comment\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "be4eb9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.transform(df[\"Comment\"]).toarray()\n",
    "Y= classifier.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eb5ca55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "if(Y==0):\n",
    "    print(\"Negative\")\n",
    "elif(Y==1):\n",
    "    print(\"Neutral\")\n",
    "else:\n",
    "    print(\"Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27f0da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "# y_pred = classifier.predict(X_test)\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98f707d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_score = accuracy_score(y_test, y_pred)\n",
    "# print('accuracy',nb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0543078b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the YouTube video URL: https://youtu.be/bsYWQWj-dAM?si=uqcI-UHKSh6Cgbtn\n",
      "                                               Comment\n",
      "0                          ğŸ˜®GğŸ˜®ğŸ˜®ğŸ˜®ğŸ‘€ğŸ˜®ğŸ˜®ğŸ˜‰Gle ğŸ˜ŠğŸ‰ğŸ‰ğŸ‰ team 0:47\n",
      "1    Hey Google\\nKindly launch Pixel phone in 256/5...\n",
      "2    Yeah the build quality and feel in hand the pi...\n",
      "3    i could never own that kind of phone. It doesn...\n",
      "4                                                     \n",
      "..                                                 ...\n",
      "397                                   its finally here\n",
      "398                 Looks amazing and love the colors!\n",
      "399                                   First comment ğŸ‰ğŸ‰\n",
      "400                                         Ğ£Ğ ĞĞĞ!!!!!\n",
      "401                                           Good job\n",
      "\n",
      "[402 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "import re\n",
    "\n",
    "# Prompt the user for the YouTube API key\n",
    "API_KEY = 'YOUR - API - KEY'\n",
    "\n",
    "def extract_video_id(url):\n",
    "    # Regular expression to extract the video ID from various YouTube URL formats\n",
    "    video_id_match = re.search(r\"(?:v=|v\\/|vi\\/|videos\\/|embed\\/|youtu.be\\/|watch\\?v=|\\?v=|&v=|\\?id=)([a-zA-Z0-9_-]+)\", url)\n",
    "\n",
    "    if video_id_match:\n",
    "        return video_id_match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_youtube_comments(api_key, video_id, max_comments):\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    # Retrieve video comments\n",
    "    comments = []\n",
    "    nextPageToken = None\n",
    "    total_comments_retrieved = 0\n",
    "\n",
    "    while True and total_comments_retrieved < max_comments:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part='snippet',\n",
    "            videoId=video_id,\n",
    "            textFormat='plainText',\n",
    "            pageToken=nextPageToken\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comments.append(comment)\n",
    "            total_comments_retrieved += 1\n",
    "\n",
    "            if total_comments_retrieved >= max_comments:\n",
    "                break\n",
    "\n",
    "        nextPageToken = response.get('nextPageToken')\n",
    "\n",
    "        if not nextPageToken or total_comments_retrieved >= max_comments:\n",
    "            break\n",
    "\n",
    "    return comments\n",
    "\n",
    "# Prompt the user for the YouTube video URL\n",
    "youtube_url = input(\"Enter the YouTube video URL: \")\n",
    "\n",
    "# Extract the video ID from the URL\n",
    "video_id = extract_video_id(youtube_url)\n",
    "\n",
    "if video_id:\n",
    "    MAX_COMMENTS = 2000  # Maximum comments to retrieve\n",
    "    # Fetch YouTube comments for the specified video\n",
    "    comments = get_youtube_comments(API_KEY, video_id, MAX_COMMENTS)\n",
    "\n",
    "    # Create a DataFrame from the comments\n",
    "    df = pd.DataFrame(comments, columns=['Comment'])\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Invalid YouTube video URL. Please provide a valid URL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3a5a672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğŸ˜®GğŸ˜®ğŸ˜®ğŸ˜®ğŸ‘€ğŸ˜®ğŸ˜®ğŸ˜‰Gle ğŸ˜ŠğŸ‰ğŸ‰ğŸ‰ team 0:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey Google\\nKindly launch Pixel phone in 256/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yeah the build quality and feel in hand the pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i could never own that kind of phone. It doesn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>its finally here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Looks amazing and love the colors!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>First comment ğŸ‰ğŸ‰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Ğ£Ğ ĞĞĞ!!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Good job</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comment\n",
       "0                          ğŸ˜®GğŸ˜®ğŸ˜®ğŸ˜®ğŸ‘€ğŸ˜®ğŸ˜®ğŸ˜‰Gle ğŸ˜ŠğŸ‰ğŸ‰ğŸ‰ team 0:47\n",
       "1    Hey Google\\nKindly launch Pixel phone in 256/5...\n",
       "2    Yeah the build quality and feel in hand the pi...\n",
       "3    i could never own that kind of phone. It doesn...\n",
       "4                                                     \n",
       "..                                                 ...\n",
       "397                                   its finally here\n",
       "398                 Looks amazing and love the colors!\n",
       "399                                   First comment ğŸ‰ğŸ‰\n",
       "400                                         Ğ£Ğ ĞĞĞ!!!!!\n",
       "401                                           Good job\n",
       "\n",
       "[402 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'text': 'Comment'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09cc0744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğŸ˜®GğŸ˜®ğŸ˜®ğŸ˜®ğŸ‘€ğŸ˜®ğŸ˜®ğŸ˜‰Gle ğŸ˜ŠğŸ‰ğŸ‰ğŸ‰ team 0:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey Google\\nKindly launch Pixel phone in 256/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yeah the build quality and feel in hand the pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i could never own that kind of phone. It doesn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment\n",
       "0                        ğŸ˜®GğŸ˜®ğŸ˜®ğŸ˜®ğŸ‘€ğŸ˜®ğŸ˜®ğŸ˜‰Gle ğŸ˜ŠğŸ‰ğŸ‰ğŸ‰ team 0:47\n",
       "1  Hey Google\\nKindly launch Pixel phone in 256/5...\n",
       "2  Yeah the build quality and feel in hand the pi...\n",
       "3  i could never own that kind of phone. It doesn...\n",
       "4                                                   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0712888",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_processing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mComment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComment\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[43mtext_processing\u001b[49m(x))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_processing' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"Comment\"] = df[\"Comment\"].apply(lambda x : text_processing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f961f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğŸ˜®GğŸ˜®ğŸ˜®ğŸ˜®ğŸ‘€ğŸ˜®ğŸ˜®ğŸ˜‰Gle ğŸ˜ŠğŸ‰ğŸ‰ğŸ‰ team 0:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey Google\\nKindly launch Pixel phone in 256/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yeah the build quality and feel in hand the pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i could never own that kind of phone. It doesn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>its finally here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Looks amazing and love the colors!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>First comment ğŸ‰ğŸ‰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Ğ£Ğ ĞĞĞ!!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Good job</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comment\n",
       "0                          ğŸ˜®GğŸ˜®ğŸ˜®ğŸ˜®ğŸ‘€ğŸ˜®ğŸ˜®ğŸ˜‰Gle ğŸ˜ŠğŸ‰ğŸ‰ğŸ‰ team 0:47\n",
       "1    Hey Google\\nKindly launch Pixel phone in 256/5...\n",
       "2    Yeah the build quality and feel in hand the pi...\n",
       "3    i could never own that kind of phone. It doesn...\n",
       "4                                                     \n",
       "..                                                 ...\n",
       "397                                   its finally here\n",
       "398                 Looks amazing and love the colors!\n",
       "399                                   First comment ğŸ‰ğŸ‰\n",
       "400                                         Ğ£Ğ ĞĞĞ!!!!!\n",
       "401                                           Good job\n",
       "\n",
       "[402 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7821d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.transform(df[\"Comment\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74d65033",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= classifier.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbf85f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, ..., 1, 2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98497689",
   "metadata": {},
   "outputs": [],
   "source": [
    "nega = np.sum(Y == 0)\n",
    "neu=np.sum(Y==1)\n",
    "pos=np.sum(Y==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14b6f381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1c18d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "892"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7062cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eaed5d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos+neu+nega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e099b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
